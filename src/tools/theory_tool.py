"""
Theory Tool - å’Œå¼¦è¯†åˆ«ä¸ä¹ç†åˆ†æ
ä½¿ç”¨ Librosa è¿›è¡Œå’Œå¼¦è¯†åˆ«å’ŒéŸ³ä¹ç†è®ºåˆ†æ
"""

import os
from typing import Dict, Any, Optional, List, ClassVar
from pathlib import Path

from langchain.tools import BaseTool
from pydantic import BaseModel, Field
import numpy as np


class TheoryToolInput(BaseModel):
    """Theory Tool è¾“å…¥å‚æ•°"""
    audio_path: str = Field(description="éŸ³é¢‘æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ (æ”¯æŒ .wav, .mp3, .flac ç­‰æ ¼å¼)")
    analysis_type: str = Field(
        default="chords",
        description="åˆ†æç±»å‹: 'chords' (å’Œå¼¦è¯†åˆ«), 'key' (è°ƒæ€§åˆ†æ), 'tempo' (èŠ‚å¥åˆ†æ), 'all' (å…¨éƒ¨)"
    )


class TheoryTool(BaseTool):
    """
    ä¹ç†å·¥å…· - å’Œå¼¦è¯†åˆ«ä¸éŸ³ä¹åˆ†æ

    è¿™ä¸ªå·¥å…·ä½¿ç”¨ Librosa æ¥åˆ†æéŸ³é¢‘æ–‡ä»¶ï¼Œè¯†åˆ«å’Œå¼¦ã€è°ƒæ€§å’ŒèŠ‚å¥ç­‰éŸ³ä¹ç†è®ºå…ƒç´ ã€‚

    åŠŸèƒ½ï¼š
    - å’Œå¼¦è¯†åˆ« (Chord Recognition)
    - è°ƒæ€§åˆ†æ (Key Detection)
    - èŠ‚å¥åˆ†æ (Tempo Analysis)
    - éŸ³é«˜ç±»åˆ«åˆ†æ (Pitch Class Profile)
    """

    name: str = "theory_tool"
    description: str = """
    åˆ†æéŸ³é¢‘æ–‡ä»¶çš„éŸ³ä¹ç†è®ºå…ƒç´ ï¼ˆå’Œå¼¦ã€è°ƒæ€§ã€èŠ‚å¥ï¼‰ã€‚

    è¾“å…¥ï¼šéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    è¾“å‡ºï¼šå’Œå¼¦åºåˆ—ã€è°ƒæ€§ã€èŠ‚å¥ç­‰éŸ³ä¹ç†è®ºä¿¡æ¯çš„ JSON æ ¼å¼

    ä½¿ç”¨åœºæ™¯ï¼š
    - è¯†åˆ«éŸ³é¢‘ä¸­çš„å’Œå¼¦è¿›è¡Œ
    - åˆ†æéŸ³ä¹çš„è°ƒæ€§
    - æ£€æµ‹èŠ‚å¥å’Œé€Ÿåº¦
    - ä¸ºç¼–æ›²æä¾›ä¹ç†ä¾æ®

    ç¤ºä¾‹ï¼š
    è¾“å…¥: "/path/to/audio.wav"
    è¾“å‡º: {"chords": ["C", "Am", "F", "G"], "key": "C major", "tempo": 120}
    """
    args_schema: type[BaseModel] = TheoryToolInput

    # å’Œå¼¦æ¨¡æ¿ (12ä¸ªåŠéŸ³çš„éŸ³é«˜ç±»åˆ«åˆ†å¸ƒ)
    CHORD_TEMPLATES: ClassVar[Dict[str, List[int]]] = {
        'C': [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],      # C major (C-E-G)
        'Cm': [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],     # C minor (C-Eb-G)
        'C#': [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],     # C# major
        'C#m': [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],    # C# minor
        'D': [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0],      # D major
        'Dm': [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0],     # D minor
        'D#': [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],     # D# major
        'D#m': [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],    # D# minor
        'E': [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],      # E major
        'Em': [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],     # E minor
        'F': [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],      # F major
        'Fm': [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],     # F minor
        'F#': [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],     # F# major
        'F#m': [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],    # F# minor
        'G': [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1],      # G major
        'Gm': [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],     # G minor
        'G#': [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],     # G# major
        'G#m': [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],    # G# minor
        'A': [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],      # A major
        'Am': [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],     # A minor
        'A#': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],     # A# major
        'A#m': [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],    # A# minor
        'B': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],      # B major
        'Bm': [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1],     # B minor
    }

    def _run(self, audio_path: str, analysis_type: str = "chords") -> Dict[str, Any]:
        """
        æ‰§è¡ŒéŸ³ä¹ç†è®ºåˆ†æ

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            analysis_type: åˆ†æç±»å‹

        Returns:
            åŒ…å«éŸ³ä¹ç†è®ºåˆ†æç»“æœçš„å­—å…¸
        """
        try:
            # å»¶è¿Ÿå¯¼å…¥
            import librosa

            # éªŒè¯è¾“å…¥æ–‡ä»¶
            audio_path = Path(audio_path)
            if not audio_path.exists():
                return {
                    "success": False,
                    "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}"
                }

            print(f"ğŸ¼ æ­£åœ¨åˆ†æéŸ³é¢‘: {audio_path.name}")
            print(f"ğŸ“Š åˆ†æç±»å‹: {analysis_type}")

            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(str(audio_path))
            duration = librosa.get_duration(y=y, sr=sr)

            result = {
                "success": True,
                "audio_path": str(audio_path),
                "duration_seconds": round(duration, 2),
            }

            # æ ¹æ®åˆ†æç±»å‹æ‰§è¡Œä¸åŒçš„åˆ†æ
            if analysis_type in ["chords", "all"]:
                chord_result = self._analyze_chords(y, sr)
                result.update(chord_result)

            if analysis_type in ["key", "all"]:
                key_result = self._analyze_key(y, sr)
                result.update(key_result)

            if analysis_type in ["tempo", "all"]:
                tempo_result = self._analyze_tempo(y, sr)
                result.update(tempo_result)

            result["message"] = f"âœ… åˆ†æå®Œæˆï¼æ—¶é•¿ {duration:.1f} ç§’"
            print(f"âœ… åˆ†æå®Œæˆ")

            return result

        except ImportError as e:
            return {
                "success": False,
                "error": f"ç¼ºå°‘ä¾èµ–åº“: {str(e)}ã€‚è¯·è¿è¡Œ: pip install librosa"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"åˆ†æå¤±è´¥: {str(e)}"
            }

    def _analyze_chords(self, y: np.ndarray, sr: int) -> Dict[str, Any]:
        """
        å’Œå¼¦è¯†åˆ«

        ä½¿ç”¨è‰²åº¦å›¾ (Chromagram) å’Œæ¨¡æ¿åŒ¹é…è¿›è¡Œå’Œå¼¦è¯†åˆ«
        """
        import librosa

        # è®¡ç®—è‰²åº¦å›¾ (Chromagram)
        chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=512)

        # å°†è‰²åº¦å›¾åˆ†æ®µï¼Œæ¯æ®µè¯†åˆ«ä¸€ä¸ªå’Œå¼¦
        hop_length = 512
        segment_length = sr * 2  # æ¯2ç§’ä¸€ä¸ªæ®µ
        n_segments = int(len(y) / segment_length) + 1

        chords = []
        chord_times = []

        for i in range(n_segments):
            start_frame = int(i * segment_length / hop_length)
            end_frame = int((i + 1) * segment_length / hop_length)

            if start_frame >= chroma.shape[1]:
                break

            end_frame = min(end_frame, chroma.shape[1])

            # è®¡ç®—è¯¥æ®µçš„å¹³å‡è‰²åº¦
            segment_chroma = np.mean(chroma[:, start_frame:end_frame], axis=1)

            # å½’ä¸€åŒ–
            if np.sum(segment_chroma) > 0:
                segment_chroma = segment_chroma / np.sum(segment_chroma)

            # ä¸å’Œå¼¦æ¨¡æ¿åŒ¹é…
            best_chord = self._match_chord_template(segment_chroma)

            # é¿å…è¿ç»­é‡å¤çš„å’Œå¼¦
            if not chords or chords[-1] != best_chord:
                chords.append(best_chord)
                chord_times.append(round(i * 2, 1))

        return {
            "chords": chords,
            "chord_times": chord_times,
            "chord_count": len(chords),
            "chord_progression": " -> ".join(chords)
        }

    def _match_chord_template(self, chroma: np.ndarray) -> str:
        """
        å°†è‰²åº¦å‘é‡ä¸å’Œå¼¦æ¨¡æ¿åŒ¹é…

        Args:
            chroma: 12ç»´è‰²åº¦å‘é‡

        Returns:
            æœ€åŒ¹é…çš„å’Œå¼¦åç§°
        """
        best_chord = "N"  # No chord
        best_score = -1

        for chord_name, template in self.CHORD_TEMPLATES.items():
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            template_array = np.array(template)
            if np.sum(template_array) > 0:
                template_array = template_array / np.sum(template_array)

            score = np.dot(chroma, template_array)

            if score > best_score:
                best_score = score
                best_chord = chord_name

        # å¦‚æœç›¸ä¼¼åº¦å¤ªä½ï¼Œè®¤ä¸ºæ²¡æœ‰æ˜ç¡®çš„å’Œå¼¦
        if best_score < 0.3:
            return "N"

        return best_chord

    def _analyze_key(self, y: np.ndarray, sr: int) -> Dict[str, Any]:
        """
        è°ƒæ€§åˆ†æ

        ä½¿ç”¨ Krumhansl-Schmuckler ç®—æ³•ä¼°è®¡è°ƒæ€§
        """
        import librosa

        # è®¡ç®—æ•´é¦–æ›²å­çš„è‰²åº¦å›¾
        chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
        chroma_mean = np.mean(chroma, axis=1)

        # Krumhansl-Schmuckler å¤§è°ƒå’Œå°è°ƒæ¨¡æ¿
        major_profile = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])
        minor_profile = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])

        # å½’ä¸€åŒ–
        major_profile = major_profile / np.sum(major_profile)
        minor_profile = minor_profile / np.sum(minor_profile)
        chroma_mean = chroma_mean / np.sum(chroma_mean)

        # å°è¯•æ‰€æœ‰12ä¸ªè°ƒ
        note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

        best_key = "C major"
        best_score = -1

        for i in range(12):
            # æ—‹è½¬æ¨¡æ¿ä»¥åŒ¹é…ä¸åŒçš„è°ƒ
            rotated_major = np.roll(major_profile, i)
            rotated_minor = np.roll(minor_profile, i)

            # è®¡ç®—ç›¸å…³æ€§
            major_score = np.corrcoef(chroma_mean, rotated_major)[0, 1]
            minor_score = np.corrcoef(chroma_mean, rotated_minor)[0, 1]

            if major_score > best_score:
                best_score = major_score
                best_key = f"{note_names[i]} major"

            if minor_score > best_score:
                best_score = minor_score
                best_key = f"{note_names[i]} minor"

        return {
            "key": best_key,
            "key_confidence": round(float(best_score), 3)
        }

    def _analyze_tempo(self, y: np.ndarray, sr: int) -> Dict[str, Any]:
        """
        èŠ‚å¥åˆ†æ

        ä¼°è®¡éŸ³é¢‘çš„é€Ÿåº¦ (BPM) å’ŒèŠ‚æ‹
        """
        import librosa

        # ä¼°è®¡é€Ÿåº¦
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

        # è®¡ç®—èŠ‚æ‹æ—¶é—´
        beat_times = librosa.frames_to_time(beats, sr=sr)

        return {
            "tempo": round(float(tempo), 1),
            "beat_count": len(beats),
            "beat_times": [round(float(t), 2) for t in beat_times[:10]],  # åªè¿”å›å‰10ä¸ªèŠ‚æ‹
        }

    async def _arun(self, audio_path: str, analysis_type: str = "chords") -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œï¼ˆå½“å‰ä½¿ç”¨åŒæ­¥å®ç°ï¼‰"""
        return self._run(audio_path, analysis_type)


# ä¾¿æ·å‡½æ•°ï¼šç›´æ¥è°ƒç”¨å·¥å…·
def analyze_music_theory(audio_path: str, analysis_type: str = "chords") -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æéŸ³ä¹ç†è®º

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        analysis_type: åˆ†æç±»å‹

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    tool = TheoryTool()
    return tool._run(audio_path, analysis_type)
